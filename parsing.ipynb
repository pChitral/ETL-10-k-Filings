{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-09-12 15:12:57,401:INFO - Initializing default bucket(InMemoryBucket) with rates: [limit=10/1000]\n",
      "2023-09-12 15:12:57,401:INFO - (sync)leaking bucket: <pyrate_limiter.buckets.in_memory_bucket.InMemoryBucket object at 0x12647e850>, 0 items\n",
      "2023-09-12 15:12:59,407:INFO - (sync)leaking bucket: <pyrate_limiter.buckets.in_memory_bucket.InMemoryBucket object at 0x12647e850>, 4 items\n",
      "2023-09-12 15:13:01,412:INFO - (sync)leaking bucket: <pyrate_limiter.buckets.in_memory_bucket.InMemoryBucket object at 0x12647e850>, 8 items\n",
      "2023-09-12 15:13:03,418:INFO - (sync)leaking bucket: <pyrate_limiter.buckets.in_memory_bucket.InMemoryBucket object at 0x12647e850>, 8 items\n",
      "2023-09-12 15:13:05,423:INFO - (sync)leaking bucket: <pyrate_limiter.buckets.in_memory_bucket.InMemoryBucket object at 0x12647e850>, 9 items\n",
      "2023-09-12 15:13:07,425:INFO - (sync)leaking bucket: <pyrate_limiter.buckets.in_memory_bucket.InMemoryBucket object at 0x12647e850>, 10 items\n",
      "2023-09-12 15:13:09,430:INFO - (sync)leaking bucket: <pyrate_limiter.buckets.in_memory_bucket.InMemoryBucket object at 0x12647e850>, 11 items\n",
      "Collecting Tickers: 100%|██████████| 1/1 [00:00<00:00, 893.74ticker/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files are ready for AAPL\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/chitralpatil/Documents/Research/ETL-10-k-Filings/venv/lib/python3.11/site-packages/bs4/builder/__init__.py:545: XMLParsedAsHTMLWarning: It looks like you're parsing an XML document using an HTML parser. If this really is an HTML document (maybe it's XHTML?), you can ignore or filter this warning. If it's XML, you should know that using an XML parser will be more reliable. To parse this document as XML, make sure you have the lxml package installed, and pass the keyword argument `features=\"xml\"` into the BeautifulSoup constructor.\n",
      "  warnings.warn(\n",
      "2023-09-12 15:13:11,442:INFO - (sync)leaking bucket: <pyrate_limiter.buckets.in_memory_bucket.InMemoryBucket object at 0x12647e850>, 7 items\n",
      "2023-09-12 15:13:13,558:INFO - (sync)leaking bucket: <pyrate_limiter.buckets.in_memory_bucket.InMemoryBucket object at 0x12647e850>, 0 items\n",
      "2023-09-12 15:13:15,657:INFO - (sync)leaking bucket: <pyrate_limiter.buckets.in_memory_bucket.InMemoryBucket object at 0x12647e850>, 0 items\n",
      "2023-09-12 15:13:15,679:INFO - HTTP Request: GET https://brezxtvmghfjdcbpdpaa.supabase.co/rest/v1/reports_10k?select=%2A \"HTTP/1.1 200 OK\"\n",
      "2023-09-12 15:13:15,870:INFO - HTTP Request: POST https://brezxtvmghfjdcbpdpaa.supabase.co/rest/v1/reports_10k \"HTTP/1.1 201 Created\"\n",
      "2023-09-12 15:13:17,662:INFO - (sync)leaking bucket: <pyrate_limiter.buckets.in_memory_bucket.InMemoryBucket object at 0x12647e850>, 4 items\n",
      "2023-09-12 15:13:19,668:INFO - (sync)leaking bucket: <pyrate_limiter.buckets.in_memory_bucket.InMemoryBucket object at 0x12647e850>, 7 items\n",
      "Collecting Tickers: 100%|██████████| 1/1 [00:00<00:00, 1592.37ticker/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files are ready for GOOG\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/chitralpatil/Documents/Research/ETL-10-k-Filings/venv/lib/python3.11/site-packages/bs4/builder/__init__.py:545: XMLParsedAsHTMLWarning: It looks like you're parsing an XML document using an HTML parser. If this really is an HTML document (maybe it's XHTML?), you can ignore or filter this warning. If it's XML, you should know that using an XML parser will be more reliable. To parse this document as XML, make sure you have the lxml package installed, and pass the keyword argument `features=\"xml\"` into the BeautifulSoup constructor.\n",
      "  warnings.warn(\n",
      "2023-09-12 15:13:21,676:INFO - (sync)leaking bucket: <pyrate_limiter.buckets.in_memory_bucket.InMemoryBucket object at 0x12647e850>, 8 items\n",
      "2023-09-12 15:13:23,575:INFO - HTTP Request: GET https://brezxtvmghfjdcbpdpaa.supabase.co/rest/v1/reports_10k?select=%2A \"HTTP/1.1 200 OK\"\n",
      "2023-09-12 15:13:23,674:INFO - HTTP Request: POST https://brezxtvmghfjdcbpdpaa.supabase.co/rest/v1/reports_10k \"HTTP/1.1 201 Created\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-09-12 15:13:23,717:INFO - (sync)leaking bucket: <pyrate_limiter.buckets.in_memory_bucket.InMemoryBucket object at 0x12647e850>, 0 items\n",
      "2023-09-12 15:13:25,722:INFO - (sync)leaking bucket: <pyrate_limiter.buckets.in_memory_bucket.InMemoryBucket object at 0x12647e850>, 0 items\n",
      "2023-09-12 15:13:27,728:INFO - (sync)leaking bucket: <pyrate_limiter.buckets.in_memory_bucket.InMemoryBucket object at 0x12647e850>, 0 items\n",
      "2023-09-12 15:13:29,734:INFO - (sync)leaking bucket: <pyrate_limiter.buckets.in_memory_bucket.InMemoryBucket object at 0x12647e850>, 0 items\n",
      "2023-09-12 15:13:31,739:INFO - (sync)leaking bucket: <pyrate_limiter.buckets.in_memory_bucket.InMemoryBucket object at 0x12647e850>, 0 items\n",
      "2023-09-12 15:13:33,745:INFO - (sync)leaking bucket: <pyrate_limiter.buckets.in_memory_bucket.InMemoryBucket object at 0x12647e850>, 0 items\n",
      "2023-09-12 15:13:35,746:INFO - (sync)leaking bucket: <pyrate_limiter.buckets.in_memory_bucket.InMemoryBucket object at 0x12647e850>, 0 items\n",
      "2023-09-12 15:13:37,752:INFO - (sync)leaking bucket: <pyrate_limiter.buckets.in_memory_bucket.InMemoryBucket object at 0x12647e850>, 0 items\n",
      "2023-09-12 15:13:39,757:INFO - (sync)leaking bucket: <pyrate_limiter.buckets.in_memory_bucket.InMemoryBucket object at 0x12647e850>, 0 items\n",
      "2023-09-12 15:13:41,762:INFO - (sync)leaking bucket: <pyrate_limiter.buckets.in_memory_bucket.InMemoryBucket object at 0x12647e850>, 0 items\n",
      "2023-09-12 15:13:43,768:INFO - (sync)leaking bucket: <pyrate_limiter.buckets.in_memory_bucket.InMemoryBucket object at 0x12647e850>, 0 items\n",
      "2023-09-12 15:13:45,773:INFO - (sync)leaking bucket: <pyrate_limiter.buckets.in_memory_bucket.InMemoryBucket object at 0x12647e850>, 0 items\n",
      "2023-09-12 15:13:47,779:INFO - (sync)leaking bucket: <pyrate_limiter.buckets.in_memory_bucket.InMemoryBucket object at 0x12647e850>, 0 items\n",
      "2023-09-12 15:13:49,779:INFO - (sync)leaking bucket: <pyrate_limiter.buckets.in_memory_bucket.InMemoryBucket object at 0x12647e850>, 0 items\n",
      "2023-09-12 15:13:51,785:INFO - (sync)leaking bucket: <pyrate_limiter.buckets.in_memory_bucket.InMemoryBucket object at 0x12647e850>, 0 items\n",
      "2023-09-12 15:13:53,787:INFO - (sync)leaking bucket: <pyrate_limiter.buckets.in_memory_bucket.InMemoryBucket object at 0x12647e850>, 0 items\n",
      "2023-09-12 15:13:55,792:INFO - (sync)leaking bucket: <pyrate_limiter.buckets.in_memory_bucket.InMemoryBucket object at 0x12647e850>, 0 items\n",
      "2023-09-12 15:13:57,793:INFO - (sync)leaking bucket: <pyrate_limiter.buckets.in_memory_bucket.InMemoryBucket object at 0x12647e850>, 0 items\n",
      "2023-09-12 15:13:59,799:INFO - (sync)leaking bucket: <pyrate_limiter.buckets.in_memory_bucket.InMemoryBucket object at 0x12647e850>, 0 items\n",
      "2023-09-12 15:14:01,800:INFO - (sync)leaking bucket: <pyrate_limiter.buckets.in_memory_bucket.InMemoryBucket object at 0x12647e850>, 0 items\n",
      "2023-09-12 15:14:03,801:INFO - (sync)leaking bucket: <pyrate_limiter.buckets.in_memory_bucket.InMemoryBucket object at 0x12647e850>, 0 items\n",
      "2023-09-12 15:14:05,807:INFO - (sync)leaking bucket: <pyrate_limiter.buckets.in_memory_bucket.InMemoryBucket object at 0x12647e850>, 0 items\n",
      "2023-09-12 15:14:07,812:INFO - (sync)leaking bucket: <pyrate_limiter.buckets.in_memory_bucket.InMemoryBucket object at 0x12647e850>, 0 items\n",
      "2023-09-12 15:14:09,818:INFO - (sync)leaking bucket: <pyrate_limiter.buckets.in_memory_bucket.InMemoryBucket object at 0x12647e850>, 0 items\n",
      "2023-09-12 15:14:11,824:INFO - (sync)leaking bucket: <pyrate_limiter.buckets.in_memory_bucket.InMemoryBucket object at 0x12647e850>, 0 items\n",
      "2023-09-12 15:14:13,829:INFO - (sync)leaking bucket: <pyrate_limiter.buckets.in_memory_bucket.InMemoryBucket object at 0x12647e850>, 0 items\n",
      "2023-09-12 15:14:15,831:INFO - (sync)leaking bucket: <pyrate_limiter.buckets.in_memory_bucket.InMemoryBucket object at 0x12647e850>, 0 items\n",
      "2023-09-12 15:14:17,836:INFO - (sync)leaking bucket: <pyrate_limiter.buckets.in_memory_bucket.InMemoryBucket object at 0x12647e850>, 0 items\n",
      "2023-09-12 15:14:19,842:INFO - (sync)leaking bucket: <pyrate_limiter.buckets.in_memory_bucket.InMemoryBucket object at 0x12647e850>, 0 items\n",
      "2023-09-12 15:14:21,846:INFO - (sync)leaking bucket: <pyrate_limiter.buckets.in_memory_bucket.InMemoryBucket object at 0x12647e850>, 0 items\n",
      "2023-09-12 15:14:23,851:INFO - (sync)leaking bucket: <pyrate_limiter.buckets.in_memory_bucket.InMemoryBucket object at 0x12647e850>, 0 items\n",
      "2023-09-12 15:14:25,857:INFO - (sync)leaking bucket: <pyrate_limiter.buckets.in_memory_bucket.InMemoryBucket object at 0x12647e850>, 0 items\n",
      "2023-09-12 15:14:27,862:INFO - (sync)leaking bucket: <pyrate_limiter.buckets.in_memory_bucket.InMemoryBucket object at 0x12647e850>, 0 items\n",
      "2023-09-12 15:14:29,868:INFO - (sync)leaking bucket: <pyrate_limiter.buckets.in_memory_bucket.InMemoryBucket object at 0x12647e850>, 0 items\n",
      "2023-09-12 15:14:31,873:INFO - (sync)leaking bucket: <pyrate_limiter.buckets.in_memory_bucket.InMemoryBucket object at 0x12647e850>, 0 items\n",
      "2023-09-12 15:14:33,879:INFO - (sync)leaking bucket: <pyrate_limiter.buckets.in_memory_bucket.InMemoryBucket object at 0x12647e850>, 0 items\n",
      "2023-09-12 15:14:35,884:INFO - (sync)leaking bucket: <pyrate_limiter.buckets.in_memory_bucket.InMemoryBucket object at 0x12647e850>, 0 items\n",
      "2023-09-12 15:14:37,890:INFO - (sync)leaking bucket: <pyrate_limiter.buckets.in_memory_bucket.InMemoryBucket object at 0x12647e850>, 0 items\n",
      "2023-09-12 15:14:39,892:INFO - (sync)leaking bucket: <pyrate_limiter.buckets.in_memory_bucket.InMemoryBucket object at 0x12647e850>, 0 items\n",
      "2023-09-12 15:14:41,898:INFO - (sync)leaking bucket: <pyrate_limiter.buckets.in_memory_bucket.InMemoryBucket object at 0x12647e850>, 0 items\n",
      "2023-09-12 15:14:43,899:INFO - (sync)leaking bucket: <pyrate_limiter.buckets.in_memory_bucket.InMemoryBucket object at 0x12647e850>, 0 items\n",
      "2023-09-12 15:14:45,905:INFO - (sync)leaking bucket: <pyrate_limiter.buckets.in_memory_bucket.InMemoryBucket object at 0x12647e850>, 0 items\n",
      "2023-09-12 15:14:47,910:INFO - (sync)leaking bucket: <pyrate_limiter.buckets.in_memory_bucket.InMemoryBucket object at 0x12647e850>, 0 items\n",
      "2023-09-12 15:14:49,916:INFO - (sync)leaking bucket: <pyrate_limiter.buckets.in_memory_bucket.InMemoryBucket object at 0x12647e850>, 0 items\n",
      "2023-09-12 15:14:51,922:INFO - (sync)leaking bucket: <pyrate_limiter.buckets.in_memory_bucket.InMemoryBucket object at 0x12647e850>, 0 items\n",
      "2023-09-12 15:14:53,928:INFO - (sync)leaking bucket: <pyrate_limiter.buckets.in_memory_bucket.InMemoryBucket object at 0x12647e850>, 0 items\n",
      "2023-09-12 15:14:55,929:INFO - (sync)leaking bucket: <pyrate_limiter.buckets.in_memory_bucket.InMemoryBucket object at 0x12647e850>, 0 items\n",
      "2023-09-12 15:14:57,935:INFO - (sync)leaking bucket: <pyrate_limiter.buckets.in_memory_bucket.InMemoryBucket object at 0x12647e850>, 0 items\n",
      "2023-09-12 15:14:59,938:INFO - (sync)leaking bucket: <pyrate_limiter.buckets.in_memory_bucket.InMemoryBucket object at 0x12647e850>, 0 items\n",
      "2023-09-12 15:15:01,943:INFO - (sync)leaking bucket: <pyrate_limiter.buckets.in_memory_bucket.InMemoryBucket object at 0x12647e850>, 0 items\n",
      "2023-09-12 15:15:03,948:INFO - (sync)leaking bucket: <pyrate_limiter.buckets.in_memory_bucket.InMemoryBucket object at 0x12647e850>, 0 items\n",
      "2023-09-12 15:15:05,950:INFO - (sync)leaking bucket: <pyrate_limiter.buckets.in_memory_bucket.InMemoryBucket object at 0x12647e850>, 0 items\n",
      "2023-09-12 15:15:07,951:INFO - (sync)leaking bucket: <pyrate_limiter.buckets.in_memory_bucket.InMemoryBucket object at 0x12647e850>, 0 items\n",
      "2023-09-12 15:15:09,956:INFO - (sync)leaking bucket: <pyrate_limiter.buckets.in_memory_bucket.InMemoryBucket object at 0x12647e850>, 0 items\n",
      "2023-09-12 15:15:11,962:INFO - (sync)leaking bucket: <pyrate_limiter.buckets.in_memory_bucket.InMemoryBucket object at 0x12647e850>, 0 items\n",
      "2023-09-12 15:15:13,964:INFO - (sync)leaking bucket: <pyrate_limiter.buckets.in_memory_bucket.InMemoryBucket object at 0x12647e850>, 0 items\n",
      "2023-09-12 15:15:15,969:INFO - (sync)leaking bucket: <pyrate_limiter.buckets.in_memory_bucket.InMemoryBucket object at 0x12647e850>, 0 items\n",
      "2023-09-12 15:15:17,973:INFO - (sync)leaking bucket: <pyrate_limiter.buckets.in_memory_bucket.InMemoryBucket object at 0x12647e850>, 0 items\n",
      "2023-09-12 15:15:19,977:INFO - (sync)leaking bucket: <pyrate_limiter.buckets.in_memory_bucket.InMemoryBucket object at 0x12647e850>, 0 items\n",
      "2023-09-12 15:15:21,982:INFO - (sync)leaking bucket: <pyrate_limiter.buckets.in_memory_bucket.InMemoryBucket object at 0x12647e850>, 0 items\n",
      "2023-09-12 15:15:23,987:INFO - (sync)leaking bucket: <pyrate_limiter.buckets.in_memory_bucket.InMemoryBucket object at 0x12647e850>, 0 items\n",
      "2023-09-12 15:15:25,992:INFO - (sync)leaking bucket: <pyrate_limiter.buckets.in_memory_bucket.InMemoryBucket object at 0x12647e850>, 0 items\n",
      "2023-09-12 15:15:27,998:INFO - (sync)leaking bucket: <pyrate_limiter.buckets.in_memory_bucket.InMemoryBucket object at 0x12647e850>, 0 items\n",
      "2023-09-12 15:15:30,003:INFO - (sync)leaking bucket: <pyrate_limiter.buckets.in_memory_bucket.InMemoryBucket object at 0x12647e850>, 0 items\n",
      "2023-09-12 15:15:32,009:INFO - (sync)leaking bucket: <pyrate_limiter.buckets.in_memory_bucket.InMemoryBucket object at 0x12647e850>, 0 items\n",
      "2023-09-12 15:15:34,014:INFO - (sync)leaking bucket: <pyrate_limiter.buckets.in_memory_bucket.InMemoryBucket object at 0x12647e850>, 0 items\n",
      "2023-09-12 15:15:36,020:INFO - (sync)leaking bucket: <pyrate_limiter.buckets.in_memory_bucket.InMemoryBucket object at 0x12647e850>, 0 items\n",
      "2023-09-12 15:15:38,025:INFO - (sync)leaking bucket: <pyrate_limiter.buckets.in_memory_bucket.InMemoryBucket object at 0x12647e850>, 0 items\n",
      "2023-09-12 15:15:40,031:INFO - (sync)leaking bucket: <pyrate_limiter.buckets.in_memory_bucket.InMemoryBucket object at 0x12647e850>, 0 items\n",
      "2023-09-12 15:15:42,036:INFO - (sync)leaking bucket: <pyrate_limiter.buckets.in_memory_bucket.InMemoryBucket object at 0x12647e850>, 0 items\n",
      "2023-09-12 15:15:44,042:INFO - (sync)leaking bucket: <pyrate_limiter.buckets.in_memory_bucket.InMemoryBucket object at 0x12647e850>, 0 items\n",
      "2023-09-12 15:15:46,047:INFO - (sync)leaking bucket: <pyrate_limiter.buckets.in_memory_bucket.InMemoryBucket object at 0x12647e850>, 0 items\n",
      "2023-09-12 15:15:48,048:INFO - (sync)leaking bucket: <pyrate_limiter.buckets.in_memory_bucket.InMemoryBucket object at 0x12647e850>, 0 items\n",
      "2023-09-12 15:15:50,054:INFO - (sync)leaking bucket: <pyrate_limiter.buckets.in_memory_bucket.InMemoryBucket object at 0x12647e850>, 0 items\n",
      "2023-09-12 15:15:52,059:INFO - (sync)leaking bucket: <pyrate_limiter.buckets.in_memory_bucket.InMemoryBucket object at 0x12647e850>, 0 items\n",
      "2023-09-12 15:15:54,065:INFO - (sync)leaking bucket: <pyrate_limiter.buckets.in_memory_bucket.InMemoryBucket object at 0x12647e850>, 0 items\n",
      "2023-09-12 15:15:56,070:INFO - (sync)leaking bucket: <pyrate_limiter.buckets.in_memory_bucket.InMemoryBucket object at 0x12647e850>, 0 items\n",
      "2023-09-12 15:15:58,075:INFO - (sync)leaking bucket: <pyrate_limiter.buckets.in_memory_bucket.InMemoryBucket object at 0x12647e850>, 0 items\n",
      "2023-09-12 15:16:00,081:INFO - (sync)leaking bucket: <pyrate_limiter.buckets.in_memory_bucket.InMemoryBucket object at 0x12647e850>, 0 items\n",
      "2023-09-12 15:16:02,085:INFO - (sync)leaking bucket: <pyrate_limiter.buckets.in_memory_bucket.InMemoryBucket object at 0x12647e850>, 0 items\n",
      "2023-09-12 15:16:04,091:INFO - (sync)leaking bucket: <pyrate_limiter.buckets.in_memory_bucket.InMemoryBucket object at 0x12647e850>, 0 items\n",
      "2023-09-12 15:16:06,097:INFO - (sync)leaking bucket: <pyrate_limiter.buckets.in_memory_bucket.InMemoryBucket object at 0x12647e850>, 0 items\n",
      "2023-09-12 15:16:08,101:INFO - (sync)leaking bucket: <pyrate_limiter.buckets.in_memory_bucket.InMemoryBucket object at 0x12647e850>, 0 items\n",
      "2023-09-12 15:16:10,107:INFO - (sync)leaking bucket: <pyrate_limiter.buckets.in_memory_bucket.InMemoryBucket object at 0x12647e850>, 0 items\n",
      "2023-09-12 15:16:12,112:INFO - (sync)leaking bucket: <pyrate_limiter.buckets.in_memory_bucket.InMemoryBucket object at 0x12647e850>, 0 items\n",
      "2023-09-12 15:16:14,113:INFO - (sync)leaking bucket: <pyrate_limiter.buckets.in_memory_bucket.InMemoryBucket object at 0x12647e850>, 0 items\n",
      "2023-09-12 15:16:16,116:INFO - (sync)leaking bucket: <pyrate_limiter.buckets.in_memory_bucket.InMemoryBucket object at 0x12647e850>, 0 items\n",
      "2023-09-12 15:16:18,118:INFO - (sync)leaking bucket: <pyrate_limiter.buckets.in_memory_bucket.InMemoryBucket object at 0x12647e850>, 0 items\n",
      "2023-09-12 15:16:20,124:INFO - (sync)leaking bucket: <pyrate_limiter.buckets.in_memory_bucket.InMemoryBucket object at 0x12647e850>, 0 items\n",
      "2023-09-12 15:16:22,130:INFO - (sync)leaking bucket: <pyrate_limiter.buckets.in_memory_bucket.InMemoryBucket object at 0x12647e850>, 0 items\n",
      "2023-09-12 15:16:24,135:INFO - (sync)leaking bucket: <pyrate_limiter.buckets.in_memory_bucket.InMemoryBucket object at 0x12647e850>, 0 items\n",
      "2023-09-12 15:16:26,138:INFO - (sync)leaking bucket: <pyrate_limiter.buckets.in_memory_bucket.InMemoryBucket object at 0x12647e850>, 0 items\n",
      "2023-09-12 15:16:28,143:INFO - (sync)leaking bucket: <pyrate_limiter.buckets.in_memory_bucket.InMemoryBucket object at 0x12647e850>, 0 items\n",
      "2023-09-12 15:16:30,149:INFO - (sync)leaking bucket: <pyrate_limiter.buckets.in_memory_bucket.InMemoryBucket object at 0x12647e850>, 0 items\n",
      "2023-09-12 15:16:32,152:INFO - (sync)leaking bucket: <pyrate_limiter.buckets.in_memory_bucket.InMemoryBucket object at 0x12647e850>, 0 items\n",
      "2023-09-12 15:16:34,157:INFO - (sync)leaking bucket: <pyrate_limiter.buckets.in_memory_bucket.InMemoryBucket object at 0x12647e850>, 0 items\n",
      "2023-09-12 15:16:36,163:INFO - (sync)leaking bucket: <pyrate_limiter.buckets.in_memory_bucket.InMemoryBucket object at 0x12647e850>, 0 items\n",
      "2023-09-12 15:16:38,168:INFO - (sync)leaking bucket: <pyrate_limiter.buckets.in_memory_bucket.InMemoryBucket object at 0x12647e850>, 0 items\n",
      "2023-09-12 15:16:40,170:INFO - (sync)leaking bucket: <pyrate_limiter.buckets.in_memory_bucket.InMemoryBucket object at 0x12647e850>, 0 items\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "import re\n",
    "import pandas as pd\n",
    "from bs4 import BeautifulSoup\n",
    "from supabase import create_client\n",
    "from shutil import rmtree\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "from utils.get_ticker_10k_filings import get_ticker_10k_filings\n",
    "from utils.collect_ticker_files import collect_ticker_files\n",
    "\n",
    "# Supabase API keys\n",
    "load_dotenv()\n",
    "SUPABASE_URL = os.environ[\"SUPABASE_URL\"]\n",
    "SUPABASE_KEY = os.environ[\"SUPABASE_KEY\"]\n",
    "Client = create_client(SUPABASE_URL, SUPABASE_KEY)\n",
    "\n",
    "\n",
    "# Function to insert parsed data into Supabase\n",
    "def new_10k_reports_to_supabase(all_parsed_data_list, Client):\n",
    "    try:\n",
    "        parsed_data_df = pd.DataFrame(all_parsed_data_list)\n",
    "        existing_reports_in_supabase = Client.table(\"reports_10k\").select(\"*\").execute()\n",
    "\n",
    "        if existing_reports_in_supabase.data:\n",
    "            existing_accession_numbers = [\n",
    "                record[\"accession_number\"]\n",
    "                for record in existing_reports_in_supabase.data\n",
    "            ]\n",
    "        else:\n",
    "            existing_accession_numbers = []\n",
    "\n",
    "        filtered_reports_df = parsed_data_df[\n",
    "            ~parsed_data_df[\"accession_number\"].isin(existing_accession_numbers)\n",
    "        ]\n",
    "        formatted_filtered_reports = filtered_reports_df.to_dict(orient=\"records\")\n",
    "        data_reports = (\n",
    "            Client.table(\"reports_10k\").insert(formatted_filtered_reports).execute()\n",
    "        )\n",
    "\n",
    "        assert len(data_reports.data) > 0, \"No reports were embedded successfully.\"\n",
    "        return data_reports.data\n",
    "\n",
    "    except Exception as e:\n",
    "        return f\"An error occurred during embedding: {e}\"\n",
    "\n",
    "\n",
    "def find_general_section(title, text_content):\n",
    "    sections = re.split(r\"Item\\s+\\d+\", text_content)\n",
    "    for section in sections:\n",
    "        if re.search(re.escape(title), section, re.IGNORECASE):\n",
    "            return section.strip()\n",
    "    return None\n",
    "\n",
    "\n",
    "def delete_txt_files(files):\n",
    "    for file in files:\n",
    "        if file.endswith(\".txt\"):\n",
    "            os.remove(file)\n",
    "\n",
    "\n",
    "def parse_html_file(file_path):\n",
    "    with open(file_path, \"r\", encoding=\"utf-8\") as file:\n",
    "        soup = BeautifulSoup(file.read(), \"lxml\")\n",
    "    all_text = \" \".join([tag.strip() for tag in soup.stripped_strings])\n",
    "    risk_factors_section = find_general_section(\"Risk Factors\", all_text)\n",
    "    parsed_data = {\n",
    "        \"Risk Factors\": risk_factors_section\n",
    "        if risk_factors_section\n",
    "        else \"Section not found\"\n",
    "    }\n",
    "    return parsed_data\n",
    "\n",
    "\n",
    "def process_ticker_10k_data(ticker):\n",
    "    # Download 10-K filings\n",
    "    get_ticker_10k_filings(ticker)\n",
    "    ticker_files_dict = collect_ticker_files()\n",
    "\n",
    "    # Delete .txt files to save space\n",
    "    delete_txt_files(ticker_files_dict.get(ticker, []))\n",
    "\n",
    "    # Initialize a dictionary to hold all parsed data\n",
    "    all_parsed_data = {}\n",
    "\n",
    "    # Loop through each HTML file to parse and store the data\n",
    "    for html_file in ticker_files_dict.get(ticker, []):\n",
    "        if html_file.endswith(\".html\"):\n",
    "            path_parts = html_file.split(\"/\")\n",
    "            cik_year_acc = path_parts[4].split(\"-\")\n",
    "\n",
    "            if len(cik_year_acc) < 3:\n",
    "                print(f\"Skipping file with unexpected format: {html_file}\")\n",
    "                continue\n",
    "\n",
    "            CIK, Year, AccessionNumber = cik_year_acc\n",
    "\n",
    "            try:\n",
    "                parsed_data = parse_html_file(html_file)\n",
    "            except Exception as e:\n",
    "                print(f\"Could not parse {html_file} due to error: {e}\")\n",
    "                continue\n",
    "\n",
    "            try:\n",
    "                filing_dict = {\n",
    "                    \"ticker\": ticker,\n",
    "                    \"cik\": CIK,\n",
    "                    \"year\": int(Year),\n",
    "                    \"accession_number\": AccessionNumber,\n",
    "                    \"parsed_data\": json.dumps(parsed_data),\n",
    "                }\n",
    "            except ValueError:\n",
    "                print(f\"Skipping file with invalid year format in {html_file}\")\n",
    "                continue\n",
    "\n",
    "            all_parsed_data[AccessionNumber] = filing_dict\n",
    "\n",
    "    # Create a list of all parsed data dictionaries\n",
    "    all_parsed_data_list = list(all_parsed_data.values())\n",
    "\n",
    "    # Insert parsed data into Supabase\n",
    "    new_10k_reports_to_supabase(all_parsed_data_list, Client)\n",
    "\n",
    "    # Clear the data folder after processing\n",
    "    rmtree(\"data\")\n",
    "\n",
    "    return all_parsed_data\n",
    "\n",
    "\n",
    "# Example usage\n",
    "# Replace with your loop over tickers\n",
    "all_tickers_data = {}\n",
    "tickers = [\"AAPL\", \"GOOG\"]  # Add your list of tickers here\n",
    "\n",
    "for ticker in tickers:\n",
    "    all_tickers_data[ticker] = process_ticker_10k_data(ticker)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
